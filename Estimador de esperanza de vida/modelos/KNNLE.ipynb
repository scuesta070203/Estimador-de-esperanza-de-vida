{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wItqbOEXRuL",
        "outputId": "50d8f061-868e-4b43-e6b4-5c093a35dd3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor k encontrado: 3  |  Accuracy: 0.8515\n",
            "\n",
            "RESULTADOS FINALES KNN\n",
            "-----------------------\n",
            "Exactitud (accuracy): 0.8515\n",
            "Matriz de confusión (filas = real, columnas = predicho):\n",
            "                            Esperanza de vida muy baja  \\\n",
            "Esperanza de vida muy baja                         108   \n",
            "Esperanza de vida baja                               7   \n",
            "Esperanza de vida media                              0   \n",
            "Esperanza de vida alta                               0   \n",
            "Esperanza de vida muy alta                           0   \n",
            "\n",
            "                            Esperanza de vida baja  Esperanza de vida media  \\\n",
            "Esperanza de vida muy baja                      10                        0   \n",
            "Esperanza de vida baja                         105                        5   \n",
            "Esperanza de vida media                         11                       90   \n",
            "Esperanza de vida alta                           1                       18   \n",
            "Esperanza de vida muy alta                       0                        6   \n",
            "\n",
            "                            Esperanza de vida alta  Esperanza de vida muy alta  \n",
            "Esperanza de vida muy baja                       0                           0  \n",
            "Esperanza de vida baja                           0                           0  \n",
            "Esperanza de vida media                         17                           1  \n",
            "Esperanza de vida alta                          92                           4  \n",
            "Esperanza de vida muy alta                       7                         104  \n",
            "\n",
            "Archivos guardados:\n",
            "- life_knn_model.pkl\n",
            "- life_knn_scaler.pkl\n",
            "- life_knn_classes.pkl\n",
            "- life_knn_features.pkl\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "# 1. Cargar datos desde el Excel\n",
        "data_path = \"Life_Expectancy_Data.xlsx\"\n",
        "df = pd.read_excel(data_path)\n",
        "\n",
        "# 2. Limpiar nombres de columnas\n",
        "df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "# 3. Detectar la columna de esperanza de vida (Life Expectancy)\n",
        "target_candidates = [c for c in df.columns\n",
        "                     if \"life\" in c.lower() and \"expect\" in c.lower()]\n",
        "\n",
        "if not target_candidates:\n",
        "    raise ValueError(\"No se encontró una columna que parezca 'Life expectancy'.\")\n",
        "\n",
        "target_col = target_candidates[0]\n",
        "\n",
        "# 4. Eliminar filas sin dato de esperanza de vida\n",
        "df = df.dropna(subset=[target_col])\n",
        "\n",
        "# 5. Eliminar 'Status' si existe (para simplificar)\n",
        "if \"Status\" in df.columns:\n",
        "    df = df.drop(columns=[\"Status\"])\n",
        "\n",
        "# 6. Construir X (features) e y_cont (objetivo continua)\n",
        "X = df.drop(columns=[target_col])\n",
        "y_continua = df[target_col]\n",
        "\n",
        "# 7. One-Hot Encoding de Country (si está presente)\n",
        "if \"Country\" in X.columns:\n",
        "    X = pd.get_dummies(X, columns=[\"Country\"], drop_first=True)\n",
        "\n",
        "# 8. Rellenar NaN en columnas numéricas con la mediana\n",
        "numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
        "X[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].median())\n",
        "\n",
        "# 9. Crear variable objetivo categórica (rangos de esperanza de vida)\n",
        "etiquetas_clases = [\n",
        "    \"Esperanza de vida muy baja\",\n",
        "    \"Esperanza de vida baja\",\n",
        "    \"Esperanza de vida media\",\n",
        "    \"Esperanza de vida alta\",\n",
        "    \"Esperanza de vida muy alta\"\n",
        "]\n",
        "y = pd.qcut(y_continua, q=5, labels=etiquetas_clases)\n",
        "\n",
        "# 10. División en entrenamiento / prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# 11. Escalado de variables\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled  = scaler.transform(X_test)\n",
        "\n",
        "# 12. Búsqueda sencilla de un buen k\n",
        "mejor_k = None\n",
        "mejor_acc = -1.0\n",
        "\n",
        "for k in range(3, 26, 2):  # 3,5,7,...,25\n",
        "    modelo_temp = KNeighborsClassifier(n_neighbors=k)\n",
        "    modelo_temp.fit(X_train_scaled, y_train)\n",
        "    pred_temp = modelo_temp.predict(X_test_scaled)\n",
        "    acc = accuracy_score(y_test, pred_temp)\n",
        "\n",
        "    if acc > mejor_acc:\n",
        "        mejor_acc = acc\n",
        "        mejor_k = k\n",
        "\n",
        "print(f\"Mejor k encontrado: {mejor_k}  |  Accuracy: {mejor_acc:.4f}\")\n",
        "\n",
        "# 13. Entrenar modelo final con el mejor k\n",
        "knn_model = KNeighborsClassifier(n_neighbors=mejor_k)\n",
        "knn_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 14. Evaluación final\n",
        "y_pred = knn_model.predict(X_test_scaled)\n",
        "accuracy_final = accuracy_score(y_test, y_pred)\n",
        "matriz_conf = confusion_matrix(y_test, y_pred, labels=etiquetas_clases)\n",
        "\n",
        "print(\"\\nRESULTADOS FINALES KNN\")\n",
        "print(\"-----------------------\")\n",
        "print(f\"Exactitud (accuracy): {accuracy_final:.4f}\")\n",
        "print(\"Matriz de confusión (filas = real, columnas = predicho):\")\n",
        "print(pd.DataFrame(matriz_conf, index=etiquetas_clases, columns=etiquetas_clases))\n",
        "\n",
        "# 15. Guardar artefactos para el backend\n",
        "joblib.dump(knn_model,          \"life_knn_model.pkl\")\n",
        "joblib.dump(scaler,             \"life_knn_scaler.pkl\")\n",
        "joblib.dump(etiquetas_clases,   \"life_knn_classes.pkl\")\n",
        "joblib.dump(X.columns.tolist(), \"life_knn_features.pkl\")\n",
        "\n",
        "print(\"\\nArchivos guardados:\")\n",
        "print(\"- life_knn_model.pkl\")\n",
        "print(\"- life_knn_scaler.pkl\")\n",
        "print(\"- life_knn_classes.pkl\")\n",
        "print(\"- life_knn_features.pkl\")\n",
        "\n"
      ]
    }
  ]
}